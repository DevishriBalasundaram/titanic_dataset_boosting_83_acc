{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Start via importing libraries and accessing file path"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nsns.set()\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Titanic sink"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(url= \"https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read csv files using pandas"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/titanic/train.csv\")\ntest_df = pd.read_csv(\"../input/titanic/test.csv\")\ntrain_df.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking rows and columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Describing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check total women survived rate\nwomen_surv = train_df.loc[train_df.Sex == 'female'][\"Survived\"]\nwomen_rate = sum(women_surv)/len(women_surv)\nprint(\"Total women survived (%):\", women_rate*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing num and categ columns which is used in data preprocessing\nnum_col = train_df.select_dtypes(include=np.number).columns\nprint(\"Numerical columns: \\n\",num_col)\n\ncat_col = train_df.select_dtypes(exclude=np.number).columns\nprint(\"Categorical columns: \\n\",cat_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Survived\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### A simple bar chart to visualize survived count"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_chart(feature):\n    survived = train_df[train_df['Survived']==1][feature].value_counts()\n    dead = train_df[train_df['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',color=[\"pink\",\"grey\",\"cyan\",\"red\",\"gold\",\"black\",\"blue\"],stacked=True, figsize=(5,7)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('SibSp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Embarked')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Pclass')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Parch')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing value treatment for embarked feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"most_freq = train_df.Embarked.dropna().mode()[0]\ntrain_df['Embarked'] = train_df['Embarked'].fillna(most_freq)\ntest_df['Embarked'] = test_df['Embarked'].fillna(most_freq)\n\n# Sex and Embarked encoding\ntrain_gender_encode = train_df.replace(to_replace={'Sex': {'female': 1,'male':0}})\ntrain_data = train_gender_encode.replace(to_replace={'Embarked': {'S': 0,'C': 1,'Q': 2}})\n\ntest_gender_encode = test_df.replace(to_replace={'Sex': {'female': 1,'male':0}})\ntest_data = test_gender_encode.replace(to_replace={'Embarked': {'S': 0,'C': 1,'Q': 2}})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Processing title feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Title\n\ntrain_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntrain_data['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Title'] = test_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_data['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_map = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n             \"Master\": 3, \"Dr\": 4, \"Rev\": 4, \n             \"Col\": 4, \"Major\": 4, \"Mlle\": 4,\n             \"Countess\": 4,\"Ms\": 4, \"Lady\": 4, \n             \"Jonkheer\": 4, \"Don\": 4, \"Dona\" : 4, \n             \"Mme\": 4,\"Capt\": 4,\"Sir\": 4 }\ntrain_data['Title'] = train_data['Title'].map(title_map)\ntest_data['Title'] = test_data['Title'].map(title_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete name feature from both train and test set\ntrain_data.drop('Name', axis=1, inplace=True)\ntest_data.drop('Name', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking train data missing value\ntrain_data.isna().sum()* 100 / len(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking test data missing value\ntest_data.isna().sum()* 100 / len(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Processing cabin feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cabin\ntrain_data.Cabin.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.Pclass.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Cabin'] = train_data['Cabin'].str[:1]\ntest_data['Cabin'] = test_data['Cabin'].str[:1]\ntrain_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data\nPclass1 = train_data[train_data['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train_data[train_data['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train_data[train_data['Pclass']==3]['Cabin'].value_counts()\ntrain_data_df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ntrain_data_df.index = ['1st class','2nd class', '3rd class']\ntrain_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test data\nPclass1 = test_data[test_data['Pclass']==1]['Cabin'].value_counts()\nPclass2 = test_data[test_data['Pclass']==2]['Cabin'].value_counts()\nPclass3 = test_data[test_data['Pclass']==3]['Cabin'].value_counts()\ntest_data_df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ntest_data_df.index = ['1st class','2nd class', '3rd class']\ntest_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_df.plot(kind='bar',stacked=True, figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_df.plot(kind='bar',stacked=True, figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cabin_map = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\ntrain_data['Cabin'] = train_data['Cabin'].map(cabin_map)\ntest_data['Cabin'] = test_data['Cabin'].map(cabin_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill missing Fare with median fare for each Pclass\ntrain_data[\"Cabin\"].fillna(train_data.groupby('Pclass')['Cabin'].transform(\"median\"), inplace=True)\ntest_data[\"Cabin\"].fillna(test_data.groupby('Pclass')['Cabin'].transform(\"median\"), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing value treatment for age"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's use Title's and pclass median age for missing Age\n\ntrain_data[\"Age\"].fillna(train_data.groupby(['Title','Pclass'])['Age'].transform(\"median\"), inplace=True)\ntest_data[\"Age\"].fillna(test_data.groupby(['Title','Pclass'])['Age'].transform(\"median\"), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoding age in train data\ntrain_data.loc[train_data['Age'] <= 16, 'Age'] = 0\ntrain_data.loc[(train_data['Age'] > 16) & (train_data['Age'] <= 26), 'Age'] = 1\ntrain_data.loc[(train_data['Age'] > 26) & (train_data['Age'] <= 36), 'Age'] = 2\ntrain_data.loc[(train_data['Age'] > 36) & (train_data['Age'] <= 62), 'Age'] = 3\ntrain_data.loc[train_data['Age'] > 62, 'Age'] = 4\n\n# encoding age in test data\ntest_data.loc[test_data['Age'] <= 16, 'Age'] = 0\ntest_data.loc[(test_data['Age'] > 16) & (test_data['Age'] <= 26), 'Age'] = 1\ntest_data.loc[(test_data['Age'] > 26) & (test_data['Age'] <= 36), 'Age'] = 2\ntest_data.loc[(test_data['Age'] > 36) & (test_data['Age'] <= 62), 'Age'] = 3\ntest_data.loc[test_data['Age'] > 62, 'Age'] = 4\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isna().sum()\ntest_data['Age'].fillna((test_data['Age'].mean()), inplace=True)\ntest_data['Fare'].fillna((test_data['Fare'].mean()), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Processing Fare feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the datasets into 4 ranges using qcut\ntrain_data['Farerange'] = pd.qcut(train_data['Fare'], 4)\ntrain_data[['Farerange', 'Survived']].groupby(['Farerange'], as_index=False).mean().sort_values(by='Farerange', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorize the fare values for train data\ntrain_data.loc[ train_data['Fare'] <= 7.91, 'Fare'] = 0\ntrain_data.loc[(train_data['Fare'] > 7.91) & (train_data['Fare'] <= 14.454), 'Fare'] = 1\ntrain_data.loc[(train_data['Fare'] > 14.454) & (train_data['Fare'] <= 31), 'Fare']   = 2\ntrain_data.loc[ train_data['Fare'] > 31, 'Fare'] = 3\n\n#Categorize the fare values for test data\ntest_data.loc[ test_data['Fare'] <= 7.91, 'Fare'] = 0\ntest_data.loc[(test_data['Fare'] > 7.91) & (test_data['Fare'] <= 14.454), 'Fare'] = 1\ntest_data.loc[(test_data['Fare'] > 14.454) & (test_data['Fare'] <= 31), 'Fare']   = 2\ntest_data.loc[ test_data['Fare'] > 31, 'Fare'] = 3\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove the features of no use\ntrain_data = train_data.drop(['PassengerId','Farerange', 'Ticket'], axis=1)\ntest_data  = test_data.drop(['Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataframe into x and y\nx_train = train_data.drop('Survived', axis=1)\ny_train = train_data.Survived","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test  = test_data.copy()\nx_test.drop(['PassengerId'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"x_train\",x_train.shape)\nprint(\"y_train\",y_train.shape)\n\nprint(\"x_test\",x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_models(model,x_train,y_train,folds=10):\n    model = model.fit(x_train,y_train)\n    accuracy = round(model.score(x_train,y_train)* 100,2)\n    \n    # Performing cross validation\n    cv_score = cross_val_score(model,x_train,y_train,cv=folds,n_jobs=1)\n    cv_accuracy = round(np.mean(cv_score)*100, 2) \n    return cv_score, accuracy, cv_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_train_pred, log_acc, log_cv_acc = build_models(LogisticRegression(),x_train,y_train)\nprint(\"Accuracy: %s\" % log_acc)\nprint(\"CV Accuracy: %s\" % log_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# To find k use elbow method\ndef elbow(k):\n    accuracy = []\n    for i in k:\n        knn = KNeighborsClassifier(n_neighbors=i)\n        score = cross_val_score(knn,x_train,y_train)\n        accuracy.append(score.mean())\n    return accuracy   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_vlaue = elbow(range(1,40))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting the Curves\nplt.figure(figsize=(10,6))\nplt.plot(range(1,40),k_vlaue,marker = 'o')\nplt.xlabel('No of Neighbours')\nplt.ylabel('Accuracy')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets take k=12\nknn_train_pred, knn_acc, knn_cv_acc = build_models(KNeighborsClassifier(n_neighbors=12),x_train,y_train)\nprint(\"Accuracy: %s\" % knn_acc)\nprint(\"CV Accuracy: %s\" % knn_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_train_pred, svc_acc, svc_cv_acc = build_models(SVC(),x_train,y_train)\nprint(\"Accuracy: %s\" % svc_acc)\nprint(\"CV Accuracy: %s\" % svc_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GaussianNB"},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb_train_pred, gnb_acc, gnb_cv_acc = build_models(GaussianNB(),x_train,y_train)\nprint(\"Accuracy: %s\" % gnb_acc)\nprint(\"CV Accuracy: %s\" % gnb_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_train_pred, dt_acc, dt_cv_acc = build_models(DecisionTreeClassifier(),x_train,y_train)\nprint(\"Accuracy: %s\" % dt_acc)\nprint(\"CV Accuracy: %s\" % dt_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_train_pred, rf_acc, rf_cv_acc = build_models(RandomForestClassifier(),x_train,y_train)\nprint(\"Accuracy: %s\" % rf_acc)\nprint(\"CV Accuracy: %s\" % rf_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ada boost"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_train_pred, ada_acc, ada_cv_acc = build_models(AdaBoostClassifier(),x_train,y_train)\nprint(\"Accuracy: %s\" % ada_acc)\nprint(\"CV Accuracy: %s\" % ada_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient boost"},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_train_pred, gb_acc, gb_cv_acc = build_models(GradientBoostingClassifier(),x_train,y_train)\nprint(\"Accuracy: %s\" % gb_acc)\nprint(\"CV Accuracy: %s\" % gb_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XG boost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_train_pred, xgb_acc, xgb_cv_acc = build_models(XGBClassifier(),x_train,y_train)\nprint(\"Accuracy: %s\" % xgb_acc)\nprint(\"CV Accuracy: %s\" % xgb_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normal accuracy\nmodels = pd.DataFrame({\n    'model': ['Logistic Regression','KNN','SVC', \n              'GaussianNB','Decision Tree','Random Forest',\n              'Ada Boost','Gradient Boost','XGBoost'],\n    'accuracy': [log_acc,knn_acc,svc_acc,gnb_acc,dt_acc,rf_acc,ada_acc,gb_acc,xgb_acc]})\nmodels.sort_values(by='accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation accuracy\nmodels = pd.DataFrame({\n    'model': ['Logistic Regression','KNN','SVC', \n              'GaussianNB','Decision Tree','Random Forest',\n              'Ada Boost','Gradient Boost','XGBoost'],\n    'cv_accuracy': [log_cv_acc,knn_cv_acc,svc_cv_acc,gnb_cv_acc,dt_cv_acc,rf_cv_acc,ada_cv_acc,gb_cv_acc,xgb_cv_acc]})\nmodels.sort_values(by='cv_accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyper parameter tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets tune with the best parameters for xgb, random forest and gradient boosting\n# Random forest tuning\nparam_grid = { 'max_depth'   : [3,4,7,10,15,20,30],\n               'n_estimators' : [88,100,155,200]\n             } \nrfclassifier = RandomForestClassifier()\ngrid = GridSearchCV(rfclassifier, param_grid, refit = True, verbose = 1) \ngrid.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid.best_params_) \nprint(grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random forest\nrf_hyper_train_pred, rf_hyper_acc, rf_cv_hyper_acc = build_models(RandomForestClassifier(max_depth=4, n_estimators=100),x_train,y_train)\nprint(\"Accuracy: %s\" % rf_hyper_acc)\nprint(\"CV Accuracy: %s\" % rf_cv_hyper_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient boosting tuning\ngb_params = {'n_estimators':[90,100,150],\n             'learning_rate':[1e-2,0.1,0.5,1],\n             'max_depth':[3,4,6], \n             'min_samples_leaf':[1,3,5]}\ngbclassifier = GradientBoostingClassifier()\ngrid = GridSearchCV(gbclassifier, gb_params, refit = True, verbose = 1) \ngrid.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid.best_params_) \nprint(grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient boosting\ngb_hyper_train_pred, gb_hyper_acc, gb_cv_hyper_acc = build_models(GradientBoostingClassifier(max_depth=6, min_samples_leaf=3, n_estimators=100,learning_rate=0.1),x_train,y_train)\nprint(\"Accuracy: %s\" % gb_hyper_acc)\nprint(\"CV Accuracy: %s\" % gb_cv_hyper_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGB\nxgb_params = {'learning_rate':[0.1,0.5,1],\n              'max_depth':[4,6,9],\n              'gamma':[0,10,55,73],\n              'alpha':[0,23,67,103]}\nxgbclassifier = XGBClassifier()\ngrid = GridSearchCV(xgbclassifier, xgb_params, refit = True, verbose = 1) \ngrid.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid.best_params_) \nprint(grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XG boost\nxgb_hyper_train_pred, xgb_hyper_acc, xgb_hyper_cv_acc = build_models(XGBClassifier(alpha=0, gamma=0, learning_rate=0.5, max_depth=4),x_train,y_train)\nprint(\"Accuracy: %s\" % xgb_hyper_acc)\nprint(\"CV Accuracy: %s\" % xgb_hyper_cv_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final prediction\nall_models = pd.DataFrame({\n    'model': ['Logistic Regression','KNN','SVC', \n              'GaussianNB','Decision Tree','Random Forest',\n              'Ada Boost','Gradient Boost','XGBoost'],\n    'final_accuracy': [log_cv_acc,knn_cv_acc,svc_cv_acc,gnb_cv_acc,dt_cv_acc,rf_cv_hyper_acc,ada_cv_acc,gb_cv_hyper_acc,xgb_hyper_cv_acc]})\nall_models.sort_values(by='final_accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\n\nprint(x_test.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model testing with test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating best prediction model with test data\n# best_model =  GradientBoostingClassifier(max_depth=6, min_samples_leaf=3, n_estimators=100,learning_rate=0.1)\nbest_model = XGBClassifier(alpha=0, gamma=0, learning_rate=0.5, max_depth=4)\nbest_model.fit(x_train,y_train)\ntest_data_1 = test_data.drop(\"PassengerId\", axis=1).copy()\nprediction = best_model.predict(test_data_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_submission = pd.DataFrame({\n        \"PassengerId\": x_test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\nresult_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('submission.csv')\nsubmission.Survived.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}